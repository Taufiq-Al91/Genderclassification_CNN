{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sr2Nc56B0nCv"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/DataSets/gender-recognition-200k-images-celeba.zip\", 'r')\n",
        "zip_ref.extractall(\"/tmp\")\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkwExYdU0uHL",
        "outputId": "8257e5b2-5a4d-4804-8137-6d3e1fb3c044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "\t  rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255)\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\"/tmp/Dataset/Train\",\n",
        "                                                    batch_size = 256,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (64, 64))     \n",
        "\n",
        "validation_generator =  test_datagen.flow_from_directory( \"/tmp/Dataset/Validation\",\n",
        "                                                          batch_size  = 256,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (64, 64))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5XPtXUU0v1P",
        "outputId": "8a8a9810-e06b-4be2-f9a6-6260c7ebebed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 160000 images belonging to 2 classes.\n",
            "Found 22598 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "model = models.load_model('/content/gdrive/MyDrive/DataSets/model5.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdDvJ9n30x6E",
        "outputId": "e16ec7d8-1923-457a-e62b-d7e549c24c10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "model = tf.keras.models.Sequential([\n",
        "    # 1st conv\n",
        "  tf.keras.layers.Conv2D(96, (11,11),strides=(4,4), activation='relu', input_shape=(64, 64, 3)),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.MaxPooling2D(2, strides=(2,2)),\n",
        "    # 2nd conv\n",
        "  tf.keras.layers.Conv2D(256, (11,11),strides=(1,1), activation='relu',padding=\"same\"),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "     # 3rd conv\n",
        "  tf.keras.layers.Conv2D(384, (3,3),strides=(1,1), activation='relu',padding=\"same\"),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "    # 4th conv\n",
        "  tf.keras.layers.Conv2D(384, (3,3),strides=(1,1), activation='relu',padding=\"same\"),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "    # 5th Conv\n",
        "  tf.keras.layers.Conv2D(256, (3, 3), strides=(1, 1), activation='relu',padding=\"same\"),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.MaxPooling2D(2, strides=(2, 2)),\n",
        "  # To Flatten layer\n",
        "  tf.keras.layers.Flatten(),\n",
        "  # To FC layer 1\n",
        "  tf.keras.layers.Dense(4096, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.5),\n",
        "  #To FC layer 2\n",
        "  tf.keras.layers.Dense(4096, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.5),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "model.compile(\n",
        "    optimizer=Adam(lr=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "   )\n",
        "hist = model.fit_generator(generator=train_generator,\n",
        "                    validation_data=validation_generator,\n",
        "                    steps_per_epoch=256,\n",
        "                    validation_steps=256,\n",
        "                    epochs=5)\n",
        "\n",
        "model.save('/content/gdrive/MyDrive/DataSets/model5.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDyB-b7q0z0p",
        "outputId": "b53ab885-4e87-49f7-e1cc-e5a17bd96d5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-069ea28a2a96>:35: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  hist = model.fit_generator(generator=train_generator,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "256/256 [==============================] - ETA: 0s - loss: 0.9543 - accuracy: 0.5923"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 256 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r256/256 [==============================] - 176s 684ms/step - loss: 0.9543 - accuracy: 0.5923 - val_loss: 0.6048 - val_accuracy: 0.6388\n",
            "Epoch 2/5\n",
            "256/256 [==============================] - 132s 517ms/step - loss: 0.5378 - accuracy: 0.7306\n",
            "Epoch 3/5\n",
            "256/256 [==============================] - 132s 516ms/step - loss: 0.4908 - accuracy: 0.7666\n",
            "Epoch 4/5\n",
            "256/256 [==============================] - 132s 513ms/step - loss: 0.4475 - accuracy: 0.7905\n",
            "Epoch 5/5\n",
            "256/256 [==============================] - 131s 511ms/step - loss: 0.4170 - accuracy: 0.8097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "dNZVnSqUYjpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PsSNiaMHRsjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator( rescale = 1.0/255)\n",
        "validation_generator =  test_datagen.flow_from_directory( \"/tmp/Dataset/Validation\",\n",
        "                                                          batch_size  = 256,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (64, 64))\n",
        "\n",
        "\n",
        "scores = model.evaluate(validation_generator, steps=89)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "metadata": {
        "id": "kf5V5tl92TQ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03437ff1-b98c-4dcd-ba6d-56237505f4ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 22598 images belonging to 2 classes.\n",
            "89/89 [==============================] - 23s 252ms/step - loss: 0.4386 - accuracy: 0.7983\n",
            "Accuracy: 79.83%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_val, y_val = next(iter(validation_generator))"
      ],
      "metadata": {
        "id": "xUoHri-301nO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(x_val, y_val, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n"
      ],
      "metadata": {
        "id": "hrTj0-LY040L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "import keras.utils as image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inLine\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "   path = fn\n",
        "   img = image.load_img(path, target_size=(64, 64))\n",
        "   imgplot = plt.imshow(img)\n",
        "   x = image.img_to_array(img)\n",
        "   x = np.expand_dims(x, axis=0)\n",
        "   \n",
        "   images = np.vstack([x])\n",
        "   classes = model.predict(images, batch_size=1)\n",
        "   print(classes[0])\n",
        "   if classes[0]>0.5:\n",
        "      print(\"is a man\")\n",
        "   else:\n",
        "      print( \" is a female\")\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "JWhDwGVf09DS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}